# 3-2. 深層学習ライブラリ（その1）

## 深層学習入門

### ニューラルネットワークによるモデル

深層学習の肝は深層（人工）ニューラルネットワークを使うことで、これをどのような設計にするのかが性能に大きく影響します。ニューラルネットワークの構成パーツは
- 線形変換＋ベクトルの加算
- 非線形関数の成分毎の作用

の二つで、前者のパラメータがこれまでの機械学習における訓練パラメータ $`\theta`$ に当たるものとなります。以下で解説しますが、ニューラルネットワークの設計はsklearnのpipelineのように作るか、あるいはpythonのクラス継承で作る場合が多いです。

### モデル訓練の大枠

深層学習でモデルを得るための典型的なプロセスは以下のようなものです：

<img src="figs/DL.drawio.svg" style="width:50%">

これを $\theta$ として良さそうなものが得られるまで続けます。

- 各 $N_\text{batch}$個のデータ を **ミニバッチ** と言います。しばしば単に **バッチ** と呼ぶこともあるようです。関連して、ミニバッチに含まれるデータの数 $N_\text{batch}$ を **バッチサイズ** と呼ぶことが多いです。
- $\theta$ の更新には以下の微分更新（※）を用います<br>
        $`
        \begin{align*}
        \theta\leftarrow \theta - \eta \nabla_\theta \frac{1}{N_\text{batch}} \sum_{i=1}^{N_\text{batch}} l(f_\theta, \text{データ}_i)
        \end{align*}
        `$
    > ここで $\eta >0$ は **学習率 (learning rate)** と呼ばれます。
    
    微分の前にもう少し係数や行列をつける亜種もあります。名前をいくつか挙げておくと
    - SGD: 上の更新則そのままの手法
    - Adam や RMSprop: $\eta$ の値を、それまでの統計から適当に定めたもの

    といった感じです。

うまくパラメータが調整されたところで訓練（パラメータ更新）をやめます。得られたモデルは新データによる検証や、あるいは元データをホールドアウト検証の枠組みに乗せることで、訓練用データは全データの一部しか使用せず、残りはテスト用に回すなどします。


### 深層学習用のフレームワークとは

これらの処理は numpy や sympy を使って書くことができますが、そのようなライブラリを使ったとしても、実際にプログラムを書くのは骨の折れる仕事です。
> numpy を用いて 全て自分で作るやり方が書かれた書籍に
> - https://www.oreilly.co.jp/books/9784873117584/
>
> などがあります。動作原理を知りたい人はこれらの書籍を読んでみるといいかもしれません。

これから紹介するライブラリ（深層学習のための**フレームワーク**とも呼ばれます）は、この辺りの処理をやってくれるというわけです。深層学習フレームワークには色々あるのですが、TensorFlow, PyTorchあたりが主流で、最近では JAX+flax などを使う人も一定数いる印象です。これらの説明は次回に回すことにして、以下ではこれらのライブラリを統合して使うことのできる **Keras** と言うライブラリを紹介します。

## 深層学習ライブラリ `Keras`

深層学習ライブラリはかつで「戦国時代」があり、群雄割拠の様相だった名残で、いくつかのライブラリが存在します。どのライブラリも大体は似たような使用なのですが、細かい点で異なる部分があるため、あれもこれも使っていては面倒に感じるかもしれません。

Kerasはそのような深層学習ライブラリたちを統一的に扱うことのできるライブラリです。細かい設定に立ち入らなければ、ものすごく簡単に深層学習の実装に入門できます。それに加えて、細かい設定も可能なので、慣れれば複雑なシステムの実装も可能です。

インポートにはエイリアスを使わず、そのまま

```python
import keras
```

とすることが多いかと思います。これまで同様、このノートで全てを説明することはできないので、詳細は公式ドキュメント
- https://keras.io/api/

をみてください。

また、以後のプログラムでは以下のライブラリを使います：
```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

sns.set_theme(style="darkgrid")
```
それぞれの使い方の基本は [セクション2-1 (numpy+matplotlib)](../section2/2-1.md)、あるいは [セクション2-3（pandas+seaborn）](../section2/2-3.md) をみてください。


### 基本的な使い方

実は sklearn 風のAPI `model.fit(X, y)` が使え、ほとんどの場合これで事足りるかと思います。詳細は後々説明することにして、全体像を書くと以下のようになります。
```python
# 全体データ 
X = [x1, x2, ...]     
y = [y1, y2, ...]     

# モデルの作成（sklearn の pipeline のようなもの） 
model = keras.models.Sequential([
            層1の処理,
            層2の処理,
            ...
            層Lの処理
        ])

# 訓練
model.compile(optimizer='勾配更新名', loss='ロス関数名') 
model.fit(X, y)
```
訓練を経て、新たな入力データ `X_new` に対してモデルの出力を見たい場合は
```python
# テスト用データ
X_new = [x1_new, x2_new, ...]

# 出力
y_pred = model.predict(X_new)
```
とします。あるいは、新たな出力信号データ `y_new` もあれば、モデルの予言がどれくらいのロス関数を返すかをみることもできます：
```python
# テスト用データ
X_new = [x1_new, x2_new, ...]
y_new = [y1_new, y2_new, ...]

# 上のデータでのロス関数や精度の値
model.evaluate(X_new, y_new)
```
この際にロス関数は必ず出ますが、他にどのような値が計算されるかは、`model.compile()` でのオプション引数に依存します。

$\blacksquare$ **練習問題1:** 以下の例を実際に動かして、各段階で何をやっているのか確認してください。
- 例：人工データ分布でkerasを実際に動かしてみる

    <details>
    <summary>データの用意</summary>
    <blockquote>
    
    適当なデータ生成器を作っておきます
    ```python
    class ToyDataGenerator():
        def __init__(self, dim: int, n_class: int):
            self.rg = np.random.default_rng(seed=3)
            self.mu_for_class_np = self.rg.normal(0, 1, size=(n_class, dim))
            self.dim = dim
            self.n_class = n_class
            
        def sample(self, N_batch:int):
            x = []
            y = []
            for n in range(self.n_class):
                mu = self.mu_for_class_np[n]
                x = x + (self.rg.normal(0, .2, size=(N_batch//self.n_class,self.dim)) + mu).tolist()
                y = y + (n*np.ones(shape=(N_batch//self.n_class, 1))).tolist() 
            x = np.array(x).astype(np.float32)
            y = np.array(y).astype(np.int32)
            df = pd.DataFrame(
                {"x0": x[:, 0],
                "x1": x[:, 1],
                "y": y.reshape(-1)}
                )  
            return df
    ```
    このクラスからデータ生成器を作って、実際に訓練用データを取ってみると以下のような感じです：
    ```python
    p = ToyDataGenerator(dim=2, n_class=5)
    df = p.sample(3000)
    sns.relplot(data=df, x="x0", y="x1", hue="y")
    ```
    > <img src="figs/dl_cl1.jpg" width=40%></img>

    </blockquote>
    </details>

    <details>
    <summary>ニューラルネットの準備＋訓練</summary>
    <blockquote>

    上のデータを使ってニューラルネットを実際に訓練してみます。まずニューラルネットの作成は以下：
    ```python
    model = keras.models.Sequential([keras.layers.Input(shape=(2,)),
                                    keras.layers.Dense(10, activation='relu'),
                                    keras.layers.Dense(8, activation='relu'),
                                    keras.layers.Dense(5, activation='softmax')])

    model.summary()
    ```
    > ```
    > Model: "sequential"
    > ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
    > ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
    > ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
    > │ dense (Dense)                        │ (None, 10)                  │              30 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ dense_1 (Dense)                      │ (None, 8)                   │              88 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ dense_2 (Dense)                      │ (None, 5)                   │              45 │
    > └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
    >  Total params: 163 (652.00 B)
    >  Trainable params: 163 (652.00 B)
    >  Non-trainable params: 0 (0.00 B)
    > ```

    訓練には上で読み込んだデータ `df` を使います。
    ```python
    X_train = df[["x0", "x1"]]
    y_train = df["y"]

    # どのような訓練をするかの設定をコンパイル
    model.compile(optimizer='adam', 
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    # 訓練
    model.fit(X_train, y_train, epochs=5, batch_size=10)
    ```
    > ```
    > Epoch 1/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - accuracy: 0.4919 - loss: 1.3585
    > Epoch 2/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.7835 - loss: 0.5471
    > Epoch 3/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 4s 9ms/step - accuracy: 0.9930 - loss: 0.1890
    > Epoch 4/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step - accuracy: 0.9947 - loss: 0.0751
    > Epoch 5/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.9942 - loss: 0.0422
    > ```

    このように、エポックごとに、各ミニバッチでの精度、ロスを時々刻々計算した値を表示してくれます（しないようなオプションも可能です）。
    訓練データに対するロスが減って、精度が上がっているのがわかります。    
    
    </blockquote>
    </details>

    <details>
    <summary>できたモデルの評価</summary>
    <blockquote>
    
    新たなデータをとって、どれくらい精度良く当てられるかみてみます：
    ```python
    df_new = p.sample(300)
    X_test = df_new[["x0", "x1"]]
    y_test = df_new["y"]

    model.evaluate(X_test, y_test, return_dict=True)
    ```
    > ```
    > 10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.9966 - loss: 0.0273  
    > {'accuracy': 0.996666669845581, 'loss': 0.025339990854263306}
    > ```

    訓練データ以外でもそれなりに精度が出ています。`model.predict(X)` を使うと `X` に対する出力値も出してくれるため、それを使うと分類境界の可視化も可能です：

    ```python
    def plot_classification(model, df, x0="x0", x1="x1", hue="y", L=300):
        X0 = df[[x0]].to_numpy()
        X1 = df[[x1]].to_numpy()
        X = np.linspace(np.min(X0), np.max(X0) ,L) 
        Y = np.linspace(np.min(X1), np.max(X1), L)  
        X, Y = np.meshgrid(X, Y)        
        
        X_new = np.concatenate([X.reshape(-1, 1), Y.reshape(-1, 1)], axis=1)
        Z = model.predict(X_new).reshape(L, L, -1)
        Z = np.argmax(Z, axis=-1) # modelは最終値として確率値 p_i (i=0,...,4) を 出す（shapeで-1に対応する部分、ここが5ということ）ため、そこでの最大値を返す番号を返すようにする
        
        ax = plt.subplot()
        mappable = ax.contourf(X, Y, Z, alpha=.5)
        sns.scatterplot(data=df, x=x0, y=x1, ax=ax, hue=hue)
        plt.colorbar(mappable)

    plot_classification(model, df_new)
    ```
    > <img src="figs/dl_cl2.jpg" width=40%></img>

    これをみると クラス1と3の間の判別で少しミスがあるのがわかります。これはそもそもデータが重なっている場所なので、改善しようがないミスであることもわかります。

    </blockquote>
    </details>

> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> 特になし。
> </details>

### 層構造のAPI

ニューラルネットの処理を一つずつ見ていきます。深層ニューラルネットモデルでは、簡単な処理の部品を組み合わせてモデルを作成します：

<img src="figs/model.drawio.svg" style="width:50%">

処理の部品に対応する単位を **層（layer）** と言います。層は訓練可能なパラメータ $`\theta`$ を含むものと含まないものがあります。kerasが用意している層構造を組み合わせて全体のモデルを作成するので、まずはどのような層構造があるかを紹介します。

#### 入力のshapeに関する注意

sklearnの時と同様、ニューラルネットの全ての処理で、入力のshapeはやはり `(バッチサイズ, ベクトル次元, ...)` となっている必要があります。以下の絵では例えば入力のshapeは `(2, 4)` のケースです：

<img src="figs/process_shape.drawio.svg" style="height:28%">


これは例え1データ `x`（`バッチサイズ=1`、`次元=dim`） だけ処理する場合でも `x.shape` が `(1, dim)` となっていないといけないということです。以下で絵を使った説明をする際は基本的に `バッチサイズ=1` の場合の絵を描いています。

#### 訓練しない層

##### Activation

- 全てのニューラルネットで使用
- 詳しくは：https://keras.io/api/layers/activation_layers/

<img src="figs/activation.drawio.svg" style="height:20%">

日本語では活性化関数と言います。入力ベクトルに対して、ほとんどは成分ごとに何らかの非線形関数を作用させます。代表的な $`f`$ には以下のものがあります：
- $`\text{ReLU}(x) = \max(0, x)`$
- $`\text{LeakyReLU}(x) = \max(\alpha x, x)`$（$`\alpha \in (0, 1)`$）
- $`\text{Softmax}(\vec{x}) = \frac{1}{\sum_{i=1}^d e^{x_i}}(e^{x_1}, e^{x_2}, ..., e^{x_d})`$

上二つはベクトルへの作用は成分ごとで、そうではない活性化関数でよく使うものは Softmax だけかと思います。Softmaxは出力値を確率値にしたい場合に使います。

kerasでは以下のようにして使うことができます。

```python
act = keras.layers.f() # 活性化関数の作成
tx = act(x)            # 出力
```

<details class="memo">
<summary>例：ReLU</summary>
<blockquote>

成分ごとに作用するため、numpy配列で簡単にプロットできます。
```python
act = keras.layers.ReLU()

x = np.linspace(-2,2,100)
plt.plot(x, act(x))
```
> <img src="figs/relu.jpg" width=50%></img>

shapeが多次元でも成分ごとです：

```python
act = keras.layers.ReLU()

x = np.arange(0, 6).reshape(2, 3)
x = (-1)**x
act(x)
```
> ```
> <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
> array([[1, 0, 1],
>        [0, 1, 0]])>
> ```
</blockquote>
</details>

<details class="memo">
<summary>例：LeakyReLU</summary>
<blockquote>

```python
act = keras.layers.LeakyReLU()

x = np.linspace(-2,2,100)
plt.plot(x, act(x))
```
> <img src="figs/leaky_relu.jpg" width=50%></img>

こちらは負の方向に行くと0ではなく、少しスロープがなだらかになるようなイメージです。負の方向にも漏れ出す（＝Leakyな）ReLUということでしょう。
</blockquote>
</details>

<details class="memo">
<summary>例：Softmax</summary>
<blockquote>

こちらは成分ごとではなく、一旦成分ごとに 指数関数の肩に乗せられた後で、足して1になるように規格化されます。
```python
act = keras.layers.Softmax()
rng = np.random.default_rng(seed=1)

x = rng.uniform(-3, 3, 10)
plt.subplot(1,2,1)
plt.title("x")
plt.bar(np.arange(len(x)), x, label="x")
plt.subplot(1,2,2)
plt.title("Softmax(x)")
plt.bar(np.arange(len(x)), act(x))
```
> <img src="figs/softmax.jpg" width=50%></img>

これを見ると x が負の場合は出力値が0に近いことがわかります。
</blockquote>
</details>

なお、出力が`tf.Tensor` というクラスのオブジェクトになりますが、numpyには自動で変換してくれます。
> [!NOTE]
> 
> 次回説明しますが、実はkerasは背後で別のライブラリが動いており、デフォルトでは TensorFlow と呼ばれる深層学習用ライブラリが読み込まれるようです。ここでは活性化関数の実装も TensorFlow のものを使うため、出力が TensorFlow のオブジェクトになっているというわけです。

##### Dropout

- 全てのニューラルネットで使用
- 詳しくは：https://keras.io/api/layers/regularization_layers/

<img src="figs/dropout.drawio.svg" style="height:28%">

ドロップアウト層では、入力ベクトルをランダムに0にします。それに何の意味があるのかと思うかもしれませんが、入力情報を一定数捨てることで、基本的にはニューラルネットが入力値に過剰適合するのを防ぐ働きをします。kerasでは以下のようにして使えます：

```python
drp = keras.layers.Dropout(rate=p)
tx = drp(x, training=TrueかFalse)            # 出力
```
<details class="memo">
<summary>例：バッチサイズ1の場合（データが1個だけの場合）</summary>
<blockquote>

```python
drp = keras.layers.Dropout(rate=.1)

x = np.ones(shape=(1, 10))
drp(x, training=True)     # training=Trueに注意
```
> ```
> <tf.Tensor: shape=(1, 10), dtype=float32, numpy=
> array([[1.1111112, 1.1111112, 1.1111112, 1.1111112, 1.1111112, 1.1111112,
>         1.1111112, 1.1111112, 0.       , 1.1111112]], dtype=float32)>
> ```

この場合は `training=True` のためドロップアウトが実行されます。一方、この引数を `training=False` にすると：

```python
drp(x, training=False)     
```
> ```
> <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>
> ```

となって、恒等写像になっているのがわかります。

</blockquote>
</details>

<details class="memo">
<summary>例：バッチサイズが1ではない場合</summary>
<blockquote>

```python
drp = keras.layers.Dropout(rate=.1)

x = np.ones(shape=(3, 10))
drp(x, training=True)
```
> ```
> <tf.Tensor: shape=(3, 10), dtype=float32, numpy=
> array([[0.       , 1.1111112, 1.1111112, 1.1111112, 1.1111112, 1.1111112,
>         1.1111112, 1.1111112, 1.1111112, 1.1111112],
>        [1.1111112, 0.       , 0.       , 0.       , 1.1111112, 1.1111112,
>         1.1111112, 1.1111112, 1.1111112, 1.1111112],
>        [1.1111112, 1.1111112, 1.1111112, 1.1111112, 0.       , 1.1111112,
>         1.1111112, 0.       , 1.1111112, 1.1111112]], dtype=float32)>
> ```

3つの入力に対して、それぞれ独立に確率的なドロップアウト処理が行われているのがわかります。

</blockquote>
</details>

##### Reshape

- 全てのニューラルネットで使用
- 詳細：https://keras.io/api/layers/reshaping_layers/

<img src="figs/reshape.drawio.svg" style="height:28%">

```python
res = keras.layers.Reshape(target_shape)
tx = res(x)            # 出力
```

<details class="memo">
<summary>例：バッチサイズ1の場合（データが1個だけの場合）</summary>
<blockquote>

```python
res = keras.layers.Reshape((3,2))

x = np.arange(6).reshape(1, 6)
res(x)            
```
> ```
> <tf.Tensor: shape=(1, 3, 2), dtype=int64, numpy=
> array([[[0, 1],
>         [2, 3],
>         [4, 5]]])>
> ```

</blockquote>
</details>

<details class="memo">
<summary>例：バッチサイズが1ではない場合</summary>
<blockquote>

バッチを増やした場合、それぞれが独立にreshapeされます：

```python
x = np.arange(12).reshape(2, 6)
res(x) 
```
> ```
> <tf.Tensor: shape=(2, 3, 2), dtype=int64, numpy=
> array([[[ 0,  1],
>         [ 2,  3],
>         [ 4,  5]],
> 
>        [[ 6,  7],
>         [ 8,  9],
>         [10, 11]]])>
> ```

</blockquote>
</details>

##### Pooling

- 画像処理系のニューラルネットで使用
- 詳細：https://keras.io/api/layers/pooling_layers/

<img src="figs/pooling.gif" style="height:25%">

プーリングは主に画像処理に用います。適当なサイズの「窓」を用意して、その窓の中に入っている入力に依存した処理をし、出力画像とします。

```python
pool = keras.layers.プーリング名(
            pool_size=(H, W), 
            strides=(h, w), 
            padding="valid"か"same"
        )
y = pool(x)            # 出力
```
「窓」のサイズが `pool_size`、`strides`は2次元

<details class="memo">
<summary>例：MaxPooling</summary>
<blockquote>

MaxPoolingは `pool_size` ごとに最大値を抜き出すような操作です：
```python
mpool = keras.layers.MaxPooling2D(
    pool_size=(2, 2), strides=(1,1), padding="valid")

x = 1*(np.arange(25).reshape(1, 5, 5)%2==0).astype(np.float32)
print(f"x: \n{x.reshape(5, 5)}")

tx = mpool(x.reshape(1, 5, 5, 1))
out_shape=tx.shape
print(f"tx: \n{tx.numpy().reshape(out_shape[1], out_shape[2])}")
```
> ```
> x: 
> [[1. 0. 1. 0. 1.]
>  [0. 1. 0. 1. 0.]
>  [1. 0. 1. 0. 1.]
>  [0. 1. 0. 1. 0.]
>  [1. 0. 1. 0. 1.]]
> tx: 
> [[1. 1. 1. 1.]
>  [1. 1. 1. 1.]
>  [1. 1. 1. 1.]
>  [1. 1. 1. 1.]]
> ```

</blockquote>
</details>

<details class="memo">
<summary>例：AveragePooling</summary>
<blockquote>

例：AveragePoolingは `pool_size` ごとに平均値を返すような操作です：
```python
apool = keras.layers.AveragePooling2D(
    pool_size=(2, 2), strides=(1,1), padding="valid")

x = 1*(np.arange(25).reshape(1, 5, 5)%2==0).astype(np.float32)
print(f"x: \n{x.reshape(5, 5)}")

tx = apool(x.reshape(1, 5, 5, 1))
out_shape=tx.shape
print(f"tx: \n{tx.numpy().reshape(out_shape[1], out_shape[2])}")
```
> ```
> x: 
> [[1. 0. 1. 0. 1.]
>  [0. 1. 0. 1. 0.]
>  [1. 0. 1. 0. 1.]
>  [0. 1. 0. 1. 0.]
>  [1. 0. 1. 0. 1.]]
> tx: 
> [[0.5 0.5 0.5 0.5]
>  [0.5 0.5 0.5 0.5]
>  [0.5 0.5 0.5 0.5]
>  [0.5 0.5 0.5 0.5]]
> ```
</blockquote>
</details>

##### Attention

- 全てのニューラルネットで使用、特に言語モデルでの使用が有用
- 詳細：https://keras.io/api/layers/attention_layers/attention/

<img src="figs/attn.drawio.svg" style="height:38%">

アテンションはその名の通り、「入力のどこに注意を向けるべきか」を表したもので、クエリ $`Q`$、バリュー $`V`$、キー $`K`$ の三つの配列を入力とし、
1. $`q`$ に対して $`K = [k_1, k_2, ..., k_{T_v}]`$ を構成する $`k_i`$ に向ける注意の度合い $`p_i(q, K)`$ （確率値の場合もあれば、そうでない場合もある）を計算する
2. $`V = [v_1, v_2, ..., v_{T_v}]`$ を1で計算した $`p_i(q, K)`$ で重みづけ和（確率値の場合は平均に対応）し、出力 $`o`$ とする
3. これを $`Q = [q_1, q_2, ..., q_{T_q}]`$ の要素一つずつに適用し、出力の配列 $`O = [o_1, o_2, ..., o_{T_q}]`$ とする

という操作です。作成前にマスク（適当な要素に0掛け）が入る場合もあり、オプション変数で設定できます。`score_mode` はどのようにして $`p_i`$ を計算するかの指定です。オプションでドロップアウトなども可能なようです。

```python
attn = keras.layers.Attention(score_mode="dot")
O = attn([Q, V, K])  # 出力 
```

ここで `Q, V, K` の shape はそれぞれ `(バッチサイズ, ベクトルが何個あるか, 1ベクトルの次元)` となります。

<details>
<summary>例：適当なベクトルで計算してみる</summary>
<blockquote>

ランダムに適当な設定を作り、計算させてみます。

```python
# 設定
rng = np.random.default_rng(seed=1)
dim = 3
Tq = 5
Tv = 4

# 計算
attn = keras.layers.Attention()

Q = rng.normal(0, 1, size=(1, Tq, dim))
V = rng.normal(0, 1, size=(1, Tv, dim))
K = rng.normal(0, 1, size=(1, Tv, dim))

O, score = attn([Q, V, K], return_attention_scores=True)
O
```
> ```
> <tf.Tensor: shape=(1, 5, 3), dtype=float32, numpy=
> array([[[-0.26951313,  0.78206295,  0.62274337],
>         [ 0.01423475, -0.19782028, -0.19828793],
>         [-0.2893681 , -0.06717286,  0.02850986],
>         [-0.6165123 ,  0.23476368,  0.37249482],
>         [-1.2784956 , -0.93359005, -0.1490969 ]]], dtype=float32)>
> ```

なお、`return_attention_scores=True` とすると、重みも一緒に出力してくれます。デフォルトでは確率値なので、確認すると：
```python
np.sum(score, axis=2)
```
> ```
> array([[1.0000001 , 1.        , 1.        , 0.99999994, 1.        ]],
>       dtype=float32)
> ```
となっています。また、重みづけ和は配列についての行列積で表現できるので確認してみると：
```python
np.matmul(score, V)
```
> ```
> array([[[-0.26951313,  0.78206295,  0.62274337],
>         [ 0.01423479, -0.19782029, -0.19828795],
>         [-0.28936807, -0.06717286,  0.02850985],
>         [-0.61651229,  0.2347637 ,  0.37249481],
>         [-1.2784955 , -0.93359005, -0.14909691]]])
> ```

となっていて、`O` と同じ値になっています。

</blockquote>
</details>

$\blacksquare$ **練習問題2:** numpyで以下のような配列を作るとします：

```python
rng = np.random.default_rng(seed=1)
x = rng.normal(0, 1, size=(3, 6))
```
この配列を、6次元ベクトルのデータが3つ集まったものとみなして、以下の処理を施してください。
1. `x` に適当なactivationを作用させる
2. `x` に適当な確率でdropoutを作用させる
3. `x` の1つ1つのベクトル（shape=`(6,)`）をshape=`(3, 2)` の配列にする

> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> 
> 1. 
>     ```python
>     act = keras.layers.ReLU()
>     act(x)
>     ```
>     > ```
>     > <tf.Tensor: shape=(3, 6), dtype=float32, numpy=
>     > array([[0.34558418, 0.82161814, 0.33043706, 0.        , 0.9053559 ,
>     >         0.44637457],
>     >        [0.        , 0.5811181 , 0.3645724 , 0.2941325 , 0.02842224,
>     >         0.546713  ],
>     >        [0.        , 0.        , 0.        , 0.5988462 , 0.03972211,
>     >         0.        ]], dtype=float32)>
>     > ```
> 
> 2. 
>     ```python
>     drp = keras.layers.Dropout(rate=0.5)
>     drp(x, training=True)
>     ```
>     > ```
>     > <tf.Tensor: shape=(3, 6), dtype=float32, numpy=
>     > array([[ 0.69116837,  1.6432363 ,  0.        , -2.6063144 ,  1.8107117 ,
>     >          0.        ],
>     >        [ 0.        ,  0.        ,  0.7291448 ,  0.        ,  0.05684448,
>     >          1.093426  ],
>     >        [ 0.        , -0.3258199 ,  0.        ,  0.        ,  0.        ,
>     >         -0.5849135 ]], dtype=float32)>
>     > ```
> 3. 
>     ```python
>     res = keras.layers.Reshape((3, 2))
>     res(x)
>     ```
>     > ```
>     > <tf.Tensor: shape=(3, 3, 2), dtype=float32, numpy=
>     > array([[[ 0.34558418,  0.82161814],
>     >         [ 0.33043706, -1.3031572 ],
>     >         [ 0.9053559 ,  0.44637457]],
>     > 
>     >        [[-0.5369532 ,  0.5811181 ],
>     >         [ 0.3645724 ,  0.2941325 ],
>     >         [ 0.02842224,  0.546713  ]],
>     > 
>     >        [[-0.73645407, -0.16290995],
>     >         [-0.48211932,  0.5988462 ],
>     >         [ 0.03972211, -0.29245675]]], dtype=float32)>
>     > ```
> </details>

$\blacksquare$ **練習問題3:** numpyで以下のような配列を作るとします：

```python
rng = np.random.default_rng(seed=1)
x = rng.normal(0, 1, size=(3, 8, 8, 1))
```
この配列を、8x8（1色）画像のデータが3つ集まったものとみなして、適当なpooling処理を施してください。
> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> ```python
> pool = keras.layers.MaxPool2D(pool_size=(2, 2))
> pool(x).shape
> ```
> > ```
> > TensorShape([3, 4, 4, 1])
> > ```
> サイズが半分になっています。
> </details>

$\blacksquare$ **練習問題4:** numpyで以下のような配列を作るとします：
```python
rng = np.random.default_rng(seed=1)

Q = rng.normal(0, 1, size=(3, 2, 5))
V = rng.normal(0, 1, size=(3, 4, 5))
K = rng.normal(0, 1, size=(3, 4, 5))
``` 
これらに attention を作用させてください。

> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> ```python
> attn = keras.layers.Attention()
> attn([Q, V, K])
> ```
> > ```
> > <tf.Tensor: shape=(3, 2, 5), dtype=float32, numpy=
> > array([[[ 1.0864301 , -0.84879124, -0.7228425 ,  0.94255924,
> >           0.35209227],
> >         [ 0.631123  , -0.5753258 , -0.4464404 ,  0.80551064,
> >           0.55120134]],
> > 
> >        [[-0.10606895, -0.0634468 ,  0.1446741 , -0.98569787,
> >           0.39695987],
> >         [-0.44219097,  0.4086092 , -0.12353042, -1.2265096 ,
> >           0.08081713]],
> > 
> >        [[ 0.71163046, -0.6019023 , -0.17235962,  0.3892439 ,
> >           0.37065995],
> >         [ 0.86748666, -0.14489771, -1.3171242 , -0.395032  ,
> >           0.2785853 ]]], dtype=float32)>
> > ```
> </details>

#### 訓練可能な層

次にモデルパラメータ $`\theta`$ を含む代表的な層を紹介します。パラメータはそれぞれ
```python
layer.trainable_weights
```
でリストとして得ることができます。

##### Dense

- 全てのニューラルネットで使用
- https://keras.io/api/layers/core_layers/dense/

<img src="figs/dense.drawio.svg" style="height:20%">

これは最も単純な変換で、以下のようなベクトルの線形変換とシフトを組み合わせたものです：

$$
\begin{align*}
l: \mathbf{x} \to \mathbf{y} = W \mathbf{x} + \mathbf{b}
\end{align*}
$$

訓練可能なパラメータは $`\theta=(W, \mathbf{b})`$ です。

このような変換は以下で作成できます：
```python
l = keras.layers.Dense(units=yの次元数)
y = l(x)               # 出力
```
実際に `l` にベクトル `x` を入力する（`l(x)`とする）場合、ミニバッチで入ってくることが前提なので、`x.shape` は `(バッチサイズ, ベクトルの次元)` が想定されていることに注意です。
> なお、オプション引数の `activation` を指定すると続けて活性化関数を適用するレイヤーを一度に定義できます。

<details class="memo">
<summary>例：適当なベクトルで計算してみる</summary>
<blockquote>

以下、バッチサイズ 4, 入力ベクトルの次元3, 出力ベクトル次元2：
```python
rng = np.random.default_rng(seed=1)
bs = 4
dim = 3

l = keras.layers.Dense(units=2)
x = rng.normal(0, 1, size=(bs, dim))
l(x)
```
> ```
> <tf.Tensor: shape=(4, 2), dtype=float32, numpy=
> array([[ 0.93349534, -0.37618077],
>        [ 0.3658485 , -1.177283  ],
>        [ 0.38859648, -0.69347847],
>        [ 0.35595998, -0.32047385]], dtype=float32)>
> ```

パラメータ情報を見てみると：
```python
l.trainable_weights
```
> ```
> [<KerasVariable shape=(3, 2), dtype=float32, path=dense_1/kernel>,
>  <KerasVariable shape=(2,), dtype=float32, path=dense_1/bias>]
> ```
となって、行列 $`W`$ と ベクトル $`\mathbf{b}`$ に対応している。

</blockquote>
</details>

##### Conv

- 画像処理系のニューラルネットで使用
- https://keras.io/api/layers/convolution_layers/convolution2d/

<img src="figs/conv.gif" style="height:25%">

次に2次元畳み込み演算：

$$
\begin{align*}
\text{conv}: x_{ij}^c \to y_{IJ}^C = \sum_{c} (w^{C, c} * x^c)_{IJ} + b^C
\end{align*}
$$

です。$`ij, IJ`$ は画像の縦横の座標に対応し、$`c, C`$ はその座標上の成分（色など）を表し、$`*`$ は畳み込み演算です。

<details class="memo">
<summary>畳み込み演算の視覚的イメージ</summary>
<blockquote>

<img src="figs/convolution.drawio.svg" style="height:25%">
</blockquote>
</details>

$`c, C`$ 方向だけに注目すれば行列積になっているため、 `Dense` と同じ処理になっています。

この 各 $`w^{C, c}`$ のサイズを **カーネルサイズ**と言い、何個ずらしで畳み込みを行うかを **ストライド** と言います。また、上の図では端から順番に畳み込んでいますが、wikipediaのアニメーションでは入力画像の端に0を加えてから畳み込んでいます。これは出力画像のサイズを調整したい時に使い、**パディング**（0埋めなので特にゼロパディング）と呼ばれます。

畳み込み（2次元畳み込み）は以下で作成できます：


```python
conv = keras.layers.Conv2D(
            filters=N,        # 出力画像の枚数
            kernel_size=L,    # カーネルサイズ（自然数）
            strides=(lj, li), # ストライド（自然数のタプル）,
            padding=...       # "valid" が パディングなし
                              # "same" が パディングあり（strides=(1,1)の時に入力と出力の画像が同じサイズになるようにパディング）
    )
y = conv(x)                   # 出力
```

実際に `conv` に画像 `x` を入力する（`conv(x)`とする）場合、ミニバッチで入ってくることが前提なので、`x.shape` は `(バッチサイズ, 高さ(jの個数), 幅（iの個数）, チャンネル数（cの個数）)` が想定されていることに注意です。
> - チャンネル数がshapeの何番目であるべきかは、オプショナル引数の `data_format` を設定することで変えられるようです。
> - なお、オプション引数の `activation` を指定すると続けて活性化関数を適用するレイヤーを一度に定義できます。

<details>
<summary>例：適当な画像で計算してみる</summary>
<blockquote>

配列値を出してもよくわからないので、shapeを確認：
```python
rng = np.random.default_rng(seed=1)
bs = 1
Lj = 10
Li = 10
c = 5

conv = keras.layers.Conv2D(filters=4, kernel_size=3)
x = rng.normal(0, 1, size=(bs, Lj, Li, c))
conv(x).shape
```
> ```
> TensorShape([1, 8, 8, 4])
> ```
訓練可能なパラメータ：
```python
conv.trainable_weights
```
> ```
> [<KerasVariable shape=(3, 3, 5, 4), dtype=float32, path=conv2d_4/kernel>,
>  <KerasVariable shape=(4,), dtype=float32, path=conv2d_4/bias>]
> ```

1つ目が $`w^{C, c}`$ に対応（最初の `3, 3` が カーネルサイズ、`c`が $`c`$ の数、`filters`が $`C`$の数）し、二つ目が $`b^C`$ に対応します。

</blockquote>
</details>

##### Normalization

- 全てのニューラルネットで使用
- 詳細：https://keras.io/api/layers/normalization_layers/

基本的には入力の正規化＋パラメータですが、どの軸方向に正規化を取るかで種類があります。入力が画像 $x_{ij}^c$ の場合は正規化は チャンネル $`c`$ 方向に行います。（統計は画像の縦横$`ij`$ 方向にもとります。画像方向全てを一つのノードで表現したと思うと良いです。）

**レイヤーノルム**（最近は言語モデルで使用される）

<img src="figs/layernorm.drawio.svg" style="height:20%">

バッチ1つ当たり、ベクトルの成分方向に平均と標準偏差を計算し、まず成分方向の平均、標準偏差を 0、1 にします。その後、訓練可能なパラメータとして$`\gamma, \beta`$ の二つのベクトルを持ってきて、平均と標準偏差を全バッチ一律に再定義するような操作です。

```python
ln = keras.layers.LayerNormalization()
tx = ln(x)
```

<details>
<summary>例：適当なベクトルで計算してみる</summary>
<blockquote>

```python
rng = np.random.default_rng(seed=1)
bs = 4
dim = 3

ln = keras.layers.LayerNormalization()
x = rng.normal(0, 1, size=(bs, dim))
tx = ln(x)
tx
```
> ```
> <tf.Tensor: shape=(4, 3), dtype=float32, numpy=
> array([[-0.6672541 ,  1.400296  , -0.73304224],
>        [-1.3857579 ,  0.9339211 ,  0.45183682],
>        [-1.3874826 ,  0.91689473,  0.4705878 ],
>        [ 0.02045476, -1.2213926 ,  1.2009377 ]], dtype=float32)>
> ```

こんなふうに、出力は入力と同じ shape です。1データごと（`axis=1`）に正規化されていることを確かめてみると：

```python
print("ベクトルの成分の平均")
print(f"mean(x) = {np.mean(x, axis=1)}")
print(f"mean(tx) = {np.mean(tx, axis=1)}")
print("ベクトルの成分の標準偏差")
print(f"std(x) = {np.std(x, axis=1)}")
print(f"std(tx) = {np.std(tx, axis=1)}")
```
> ```
> ベクトルの成分の平均
> mean(x) = [0.49921314 0.01619107 0.13624576 0.28975591]
> mean(tx) = [-1.1920929e-07  0.0000000e+00 -3.9736431e-08 -3.9736431e-08]
> ベクトルの成分の標準偏差
> std(x) = [0.22805862 0.95155168 0.48416297 0.21161394]
> std(tx) = [0.99052304 0.99944824 0.9978739  0.98901796]
> ```

となって、出力ベクトルの成分方向に平均0、標準偏差1になるように処理されていることがわかります。なお、これは初期化時の状態であり、訓練をするとその後のパラメータが更新されるので、この限りではありません。その訓練パラメータ $`\theta`$ を確認してみます：
```python
ln.trainable_weights
```
> ```
> [<KerasVariable shape=(3,), dtype=float32, path=layer_normalization_1/gamma>,
>  <KerasVariable shape=(3,), dtype=float32, path=layer_normalization_1/beta>]
> ```

gamma, beta という名前のパラメータがそれぞれ shape `(3,)` で入っています。現在の値はそれぞれ全成分が 1 と 0 になっているはずです：

```python
print(ln.trainable_weights[0].value) # gamma
print(ln.trainable_weights[1].value) # beta
```
> ```
> <tf.Variable 'layer_normalization_1/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>
> <tf.Variable 'layer_normalization_1/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>
> ```

確かにそうなっています。

</blockquote>
</details>
<details>
<summary>例：適当な画像で計算してみる</summary>
<blockquote>

画像の場合は上でも書いた通り少し異なる処理で、基本的にはチャンネル方向をベクトル成分と考えます。

```python
rng = np.random.default_rng(seed=1)
bs = 4
Lj = 10
Li = 10
c = 5

ln = keras.layers.LayerNormalization()
x = rng.normal(0, 1, size=(bs, Lj, Li, c))
tx = ln(x, training=True)
tx.shape
```
> ```
> TensorShape([4, 10, 10, 5])
> ```

入力と同じshapeです。一方で訓練パラメータを見ると：
```python
ln.trainable_weights
```
> ```
> [<KerasVariable shape=(5,), dtype=float32, path=layer_normalization_2/gamma>,
>  <KerasVariable shape=(5,), dtype=float32, path=layer_normalization_2/beta>]
> ```

となって、$`\gamma, \beta`$ 両方ともチャンネル方向の数しかパラメータを持っていないことがわかります。

</blockquote>
</details>

**バッチノルム**（一昔前は画像処理などで使用されたが、最近はレイヤーノルムの方がよく使用される？）

<img src="figs/batchnorm.drawio.svg" style="height:38%">

```python
bn = keras.layers.BatchNormalization()
tx = bn(x)
```

<details>
<summary>例：適当なベクトルで計算してみる</summary>
<blockquote>

```python
rng = np.random.default_rng(seed=1)
bs = 4
dim = 3

bn = keras.layers.BatchNormalization()
x = rng.normal(0, 1, size=(bs, dim))
tx = bn(x, training=True)
tx
```
> ```
> <tf.Tensor: shape=(4, 3), dtype=float32, numpy=
> array([[ 0.9529804 ,  0.6910609 , -1.0267203 ],
>        [-1.4804415 ,  0.9347259 ,  0.2729745 ],
>        [-0.34958032, -0.00876009, -0.6440525 ],
>        [ 0.87704146, -1.617027  ,  1.397799  ]], dtype=float32)>
> ```
やはり出力のshapeは入力と同じです、1バッチごと（`axis=0`）に正規化されていることを確かめてみると：
```python
print("バッチの成分の平均")
print(f"mean(x) = {np.mean(x, axis=0)}")
print(f"mean(tx) = {np.mean(tx, axis=0)}")
print("バッチの成分の標準偏差")
print(f"std(x) = {np.std(x, axis=0)}")
print(f"std(tx) = {np.std(tx, axis=0)}")
```
> ```
> バッチの成分の平均
> mean(x) = [-0.30009844  0.58412859  0.42202426]
> mean(tx) = [ 2.9802322e-08 -8.9406967e-08  1.7881393e-07]
> バッチの成分の標準偏差
> std(x) = [0.67680197 0.34220128 0.08341035]
> std(tx) = [0.99891025 0.9957574  0.93505555]
> ```
となって、出力ベクトルのバッチ方向に平均0、標準偏差1になるように処理されていることがわかります。なお、これは初期化時の状態であり、訓練をするとその後のパラメータが更新されるので、この限りではありません。その訓練パラメータ $`\theta`$ を確認してみます：
```python
bn.trainable_weights
```
> ```
> [<KerasVariable shape=(3,), dtype=float32, path=batch_normalization_1/gamma>,
>  <KerasVariable shape=(3,), dtype=float32, path=batch_normalization_1/beta>]
> ```
gamma, beta という名前のパラメータがそれぞれ shape `(3,)` で入っています。現在の値はそれぞれ全成分が 1 と 0 になっているはずです：

```python
print(bn.trainable_weights[0].value) # gamma
print(bn.trainable_weights[1].value) # beta
```
> ```
> <tf.Variable 'batch_normalization_1/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>
> <tf.Variable 'batch_normalization_1/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>
> ```

確かにそうなっています。

</blockquote>
</details>

<details>
<summary>例：適当な画像で計算してみる</summary>
<blockquote>

画像の場合は上でも書いた通り少し異なる処理で、基本的にはチャンネル方向をベクトル成分と考えます。

```python
rng = np.random.default_rng(seed=1)
bs = 4
Lj = 10
Li = 10
c = 5

bn = keras.layers.BatchNormalization()
x = rng.normal(0, 1, size=(bs, Lj, Li, c))
tx = bn(x, training=True)
tx.shape
```
> ```
> TensorShape([4, 10, 10, 5])
> ```

入力と同じshapeです。一方で訓練パラメータを見ると：
```python
bn.trainable_weights
```
> ```
> [<KerasVariable shape=(5,), dtype=float32, path=batch_normalization_3/gamma>,
>  <KerasVariable shape=(5,), dtype=float32, path=batch_normalization_3/beta>]
> ```

となって、$`\gamma, \beta`$ 両方ともチャンネル方向の数しかパラメータを持っていないことがわかります。

</blockquote>
</details>

##### Recurrent

- 主に言語モデルなどで使用
- 詳細：https://keras.io/api/layers/recurrent_layers/

<img src="figs/rnn.drawio.svg" style="height:38%">

邦訳は再帰的ニューラルネットと言います。これまでの層では、入力→出力の処理が基本でしたが、再帰的ニューラルネットでは、出力（の一部、あるいは内部に隠された出力）を次の入力に用います。この処理を縦方向に順番に描くと上の図のようになります。

構造としては、1回あたりの処理（$\mathbf{x}_t \to \mathbf{y}_t+$内部状態更新）をするレイヤー `RNNcell` を `RNN()` でラップすると、全時刻を並べた配列の処理 $`[\mathbf{x}_0, \mathbf{x}_1, \dots, \mathbf{x}_T] \to [\mathbf{y}_0,\mathbf{y}_1, \dots, \mathbf{y}_T]`$ をする大きなニューラルネットを作ることができる、というイメージです。

```python
rnn = keras.layers.RNN(
          keras.layers.RnnCell()
     )

ys = rnn(xs) # xs = [x0, x1, ...]
```

<details>
<summary>例：RnnCellだけの処理</summary>
<blockquote>

まずは cell がどのような振る舞いをするかについてです。話をわかりやすくするためバッチサイズ1で、時系列の長さ `T` は 5、ベクトルの次元は 3 で
- 適当に `x`　を作り 
- 前の時刻の内部状態 `states` を適当に初期化
- for ループを使って毎回の処理を書く

    その際、1回のRNNcellを使った処理は
    ```python
    tx, states = cell(x, states)
    ```
    と受ける

という書き方をしたのが以下です：
```python
rng = np.random.default_rng(seed=1)
bs = 1
T  = 5
dim = 3

cell = keras.layers.SimpleRNNCell(units=3)

x = rng.normal(0, 1, size=(bs, dim))
states = cell.get_initial_state(batch_size=bs)

for t in range(T):
  tx, states = cell(x, states) # 1回前の states が代入される
  print(f"tx = {tx}")
```
> ```
> tx = [[ 0.23330611  0.219907   -0.6528118 ]]
> tx = [[ 0.46601883  0.66301507 -0.3997527 ]]
> tx = [[ 0.6773219   0.41642106 -0.1280835 ]]
> tx = [[ 0.75471187  0.26401338 -0.44682923]]
> tx = [[ 0.772421    0.55407536 -0.49489683]]
> ```

`tx, states = cell(x, states)` の部分で 内部状態 が更新されています。なお、`SimpleRNNCell` では内部状態は `tx` と同じです：
```python
tx, states = cell(x, states)
tx, states
```
> ```
> (<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.9094764 ,  0.8845763 ,  0.72256386]], dtype=float32)>,
>  [<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.9094764 ,  0.8845763 ,  0.72256386]], dtype=float32)>])
> ```
もう少し洗練された RNN もあり（LSTMなど）、その場合は両者は異なります。

なお、`states` の更新をやめて、毎回同じ `states` を入力すると、出力は同じになります：

```python
cell = keras.layers.SimpleRNNCell(units=3)
x = rng.normal(0, 1, size=(bs, dim))
states = cell.get_initial_state(batch_size=bs)

for t in range(T):
  tx, _ = cell(x, states)
  print(f"tx = {tx}")
```
> ```
> tx = [[-0.3099162   0.25869295 -0.14747381]]
> tx = [[-0.3099162   0.25869295 -0.14747381]]
> tx = [[-0.3099162   0.25869295 -0.14747381]]
> tx = [[-0.3099162   0.25869295 -0.14747381]]
> tx = [[-0.3099162   0.25869295 -0.14747381]]
> ```

このようにcellだけでも深層学習用のプログラムを書くことは可能ですが、訓練するのは今回の話だけではダメで、次回以降のライブラリの少し深い部分について理解する必要があります。

</blockquote>
</details>

<details>
<summary>例：layers.RNNでラップする処理</summary>
<blockquote>

この場合、
- forループを書かなくてよくなる
- 関連して、`states` を明示的に処理に書かなくてよくなる
- 簡単に訓練させられる

という恩恵があります。ですので、最初はこちらを使うのが良いと思います。

```python
rng = np.random.default_rng(seed=1)
bs = 1
T  = 5
dim = 3

cell = keras.layers.SimpleRNNCell(units=3)
rnn = keras.layers.RNN(cell, return_sequences=True)

xs = rng.normal(0, 1, size=(bs, T, dim))
rnn(xs)
```
> ```
> <tf.Tensor: shape=(1, 5, 3), dtype=float32, numpy=
> array([[[-0.7012051 ,  0.44930977, -0.49390155],
>         [-0.5699269 , -0.78129053,  0.9443375 ],
>         [ 0.43300432,  0.6388341 ,  0.5185464 ],
>         [-0.80768365,  0.3196442 , -0.7856061 ],
>         [ 0.4356985 , -0.74077004,  0.96214736]]], dtype=float32)>
> ```



</blockquote>
</details>

##### MultiHeadAttention

- 主に言語モデルなどで使用
- 詳細：https://keras.io/api/layers/attention_layers/multi_head_attention/

<img src="figs/multihead_attn.drawio.svg" style="height:38%">

attentionだけでは訓練可能なパラメータを持ちませんでしたが、MultiHeadAttentionでは、
- 入力配列 $`Q, V, K`$ から、各ベクトルに対して 一旦 Dense による処理をかける（2+1種類のDense）
- attentionの各出力ベクトルに対しても Dense をかける（1種類のDense）
- これを複数枚に渡って処理する

複数枚のattentionを用意するためにこのような命名になっています。

```python
attn = keras.layers.MultiHeadAttention(
            num_heads=枚数, 
            key_dim=内部でのkeyベクトルとqueryベクトルの次元, 
            value_dim=内部でのvalueベクトルの次元, 
            output_shape=出力ベクトル列の1ベクトルの次元)

O = attn(query=Q, value=V, key=K)
```
<details>
<summary>例：適当なベクトルで計算してみる</summary>
<blockquote>

```python
rng = np.random.default_rng(seed=1)
bs = 1
dim = 3
Tq = 5
Tv = 4

attn = keras.layers.MultiHeadAttention(num_heads=2, 
                                       key_dim=10, 
                                       value_dim=8, 
                                       output_shape=2)

Q = rng.normal(0, 1, size=(bs, Tq, dim))
V = rng.normal(0, 1, size=(bs, Tv, dim))
K = rng.normal(0, 1, size=(bs, Tv, dim))

O, score = attn(query=Q, value=V, key=K, 
                return_attention_scores=True) # 重みもみたい場合

O
```
> ```
> <tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=
> array([[[-0.01790731, -0.02872526],
>         [-0.07340798, -0.04997256],
>         [-0.0763535 , -0.05067822],
>         [-0.10964327, -0.0639399 ],
>         [-0.1345029 , -0.06796385]]], dtype=float32)>
> ```

この例では、バッチが1つ、ヘッドが2枚、queryの列が5個、keyの列が4個なので、重み行列は (1, 2, 5, 4) の shape となります：
```python
score
```
> ```
> <tf.Tensor: shape=(1, 2, 5, 4), dtype=float32, numpy=
> array([[[[0.22903256, 0.2666265 , 0.3013921 , 0.20294887],
>          [0.20348491, 0.30441257, 0.2630783 , 0.22902407],
>          [0.22438604, 0.2776596 , 0.26441845, 0.2335359 ],
>          [0.25529835, 0.24143142, 0.24648276, 0.25678745],
>          [0.24158053, 0.26194564, 0.23449495, 0.2619788 ]],
> 
>         [[0.27541098, 0.22988096, 0.26021335, 0.23449467],
>          [0.29920885, 0.2108361 , 0.26224878, 0.22770627],
>          [0.27567658, 0.22915898, 0.2598066 , 0.23535782],
>          [0.23793206, 0.26197267, 0.25948995, 0.24060528],
>          [0.2608526 , 0.23906659, 0.24096586, 0.25911492]]]],
>       dtype=float32)>
> ```

一応訓練パラメータもみておくと：

```python
attn.trainable_weights
```
> ```
> [<KerasVariable shape=(3, 2, 10), dtype=float32, path=multi_head_attention_10/query/kernel>,
>  <KerasVariable shape=(2, 10), dtype=float32, path=multi_head_attention_10/query/bias>,
>  <KerasVariable shape=(3, 2, 10), dtype=float32, path=multi_head_attention_10/key/kernel>,
>  <KerasVariable shape=(2, 10), dtype=float32, path=multi_head_attention_10/key/bias>,
>  <KerasVariable shape=(3, 2, 8), dtype=float32, path=multi_head_attention_10/value/kernel>,
>  <KerasVariable shape=(2, 8), dtype=float32, path=multi_head_attention_10/value/bias>,
>  <KerasVariable shape=(2, 8, 2), dtype=float32, path=multi_head_attention_10/attention_output/kernel>,
>  <KerasVariable shape=(2,), dtype=float32, path=multi_head_attention_10/attention_output/bias>]
> ```

となって、query、key、value、attention_output に関する Dense が枚数分確保されていることがわかります。

</blockquote>
</details>


$\blacksquare$ **練習問題5:** Denseレイヤーで、出力次元が3のものを作成してみてください。

> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> 素朴には
> ```python
> l = keras.layers.Dense(units=3)
> ```
> でいけそうですが、パラメータがちゃんと入っているかみてみると：
> ```python
> l.trainable_weights
> ```
> > ```
> > []
> > ```
> となって、パラメータが空であることがわかります。実は `l` を定義しただけではパラメータがセットされません。パラメータを初期化するには
> - `l.build(input_shape=(想定する入力のshape))` とするか
> - 適当な入力 `x` を実際に一回入力するか
> 
> をしないといけません。どちらのやり方でもOKです：
> - `l.build(input_shape=(想定する入力のshape))`
>     ```python
>     l = keras.layers.Dense(units=3)
>     l.build(input_shape=(1, 4))  # (データ数, 1データ次元)
>     l.trainable_weights
>     ```
>     > ```
>     > [<Variable path=dense_13/kernel, shape=(4, 3), dtype=float32, value=[[-0.7779179   0.39425468  0.2458018 ]
>     >   [ 0.6639571  -0.6203163   0.918862  ]
>     >   [ 0.7735075  -0.5043067   0.1718272 ]
>     >   [-0.659352   -0.08681506  0.70125484]]>,
>     >  <Variable path=dense_13/bias, shape=(3,), dtype=float32, value=[0. 0. 0.]>]
>     > ```
> - 適当な入力 `x` を実際に一回入力
>     ```python
>     rng = np.random.default_rng(seed=1)
>     x = rng.normal(0, 1, size=(1, 4))
>     l = keras.layers.Dense(units=3)
> 
>     l(x)
>     l.trainable_weights
>     ```
>     > ```
>     > [<Variable path=dense_14/kernel, shape=(4, 3), dtype=float32, value=[[-0.62141204 -0.7411845   0.7214519 ]
>     >   [-0.6860644   0.37894797  0.75448227]
>     >   [ 0.59674823  0.54084873  0.5401963 ]
>     >   [-0.37193245 -0.5396917  -0.47481924]]>,
>     >  <Variable path=dense_14/bias, shape=(3,), dtype=float32, value=[0. 0. 0.]>]
>     > ```
> </details>

$\blacksquare$ **練習問題6:** 適当なConvレイヤーを作成してみてください。
> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> Dense同様、レイヤー関数を作るだけではパラメータが入っていません：
> ```python
> conv = keras.layers.Conv2D(filters=4, kernel_size=3)
> conv.trainable_weights
> ```
> > ```
> > []
> > ```
> - `conv.build(input_shape)` で初期化する
>     ```python
>     conv = keras.layers.Conv2D(filters=3, kernel_size=2)
>     conv.build(input_shape=(1,8,8,1))
>     conv.trainable_weights
>     ```
>     >```
>     > [<Variable path=conv2d_14/kernel, shape=(2, 2, 1, 3), dtype=float32, value=[[[[ 0.18317747 -0.44144094 -0.01491356]]
>     >  
>     >    [[-0.42204544 -0.07361704 -0.24680135]]]
>     >  
>     >  
>     >   [[[ 0.14304209 -0.51454276  0.05954254]]
>     >  
>     >    [[ 0.5653171   0.12315315  0.55533415]]]]>,
>     >  <Variable path=conv2d_14/bias, shape=(3,), dtype=float32, value=[0. 0. 0.]>]
>     >```
> - 適当な入力をする
>     ```python
>     rng = np.random.default_rng(seed=1)
>     x = rng.normal(0, 1, size=(1, 8, 8, 1))
>     conv = keras.layers.Conv2D(filters=3, kernel_size=2)
>     
>     conv(x)
>     conv.trainable_weights
>     ```
>     > ```
>     > [<Variable path=conv2d_15/kernel, shape=(2, 2, 1, 3), dtype=float32, value=[[[[-0.5353025   0.55877024  0.3631031 ]]
>     >  
>     >    [[ 0.33003038 -0.13016424 -0.17650205]]]
>     >  
>     >  
>     >   [[[-0.49035493 -0.4476327   0.2667051 ]]
>     >  
>     >    [[ 0.46037644 -0.60025    -0.35450292]]]]>,
>     >  <Variable path=conv2d_15/bias, shape=(3,), dtype=float32, value=[0. 0. 0.]>]
>     > ```
> 
> </details>

$\blacksquare$ **練習問題7:** Layerノルムのレイヤーを
- ベクトル入力
    ```python
    rng = np.random.default_rng(seed=1)
    x = rng.normal(0, 1, size=(1, 3))
    ``` 
- 画像入力
    ```python
    rng = np.random.default_rng(seed=1)
    x_img = rng.normal(0, 1, size=(1, 8, 8, 3))
    ```
の二種類に対して定義して、それぞれ `.trainable_weights` のshapeをみてください。

> [!TIP]
> <details>
> <summary>解答例</summary>
> 
> - まずはベクトルの方を見てみます：
>     ```python
>     rng = np.random.default_rng(seed=1)
>     x = rng.normal(0, 1, size=(1, 3))
>     ln = keras.layers.LayerNormalization()
> 
>     ln(x)
>     ln.trainable_weights
>     ```
>     > ```
>     > [<Variable path=layer_normalization/gamma, shape=(3,), dtype=float32, value=[1. 1. 1.]>,
>     >  <Variable path=layer_normalization/beta, shape=(3,), dtype=float32, value=[0. 0. 0.]>]
>     > ```
> - 次に画像の方：
>     ```python
>     rng = np.random.default_rng(seed=1)
>     x_img = rng.normal(0, 1, size=(1, 8, 8, 3))
>     ln = keras.layers.LayerNormalization()
> 
>     ln(x_img)
>     ln.trainable_weights
>     ```
>     > ```
>     > [<Variable path=layer_normalization_3/gamma, shape=(3,), dtype=float32, value=[1. 1. 1.]>,
>     >  <Variable path=layer_normalization_3/beta, shape=(3,), dtype=float32, value=[0. 0. 0.]>]
>     > ```
>     shapeがベクトルの時と全く同じです。これは画像の方はshapeでいうと最後の成分だけにしか正規化は作用せず、画像の縦横方向には一律に作用することを意味します。
> 
> </details>

### モデルAPI

<img src="figs/model.drawio.svg" style="width:50%">

の図の右側の構成要素（層に当たる部分）を説明したので、次にそれを組み合わせて実際にニューラルネットワークの構成をするやり方を説明します。基本的には公式ドキュメント
- https://keras.io/api/models/

を参考にしています。sklearnのpipelineを作る作業をイメージすると良いです。

#### モデルクラス

ニューラルネットモデル（訓練前/訓練後どちらもモデルと呼ぶことにします）の本邸は **モデルクラス** のインスタンス（オブジェクト）です。このオブジェクトの内部に訓練可能なパラメータ $`\theta`$ が格納されています。ユーザーは
1. 「どのようなニューラルネットにするか」をオブジェクト作成の段階で指定 → 対応するネットワーク（ランダムなパラメータ $`\theta`$ で初期化ずみ）が作られる
2. 後でデータを使ってパラメータ $`\theta`$ を調整する＝訓練することで、望みの処理ができるようになる。
3. 場合によってはそのパラメータやオブジェクトを保存・読み込みする。

といったことが可能です。まず1のやり方ですが、大きく分けて以下のやり方があります。以下、`keras.layers.層i()` は実際には上で説明した具体的な層構造のAPIのどれかを使うことを意味します。
- 処理をベタ打ち：
    ```python
    # ニューラルネットの入力から出力までを書く
    inputs = keras.Input(shape=入力のshape)
    x = keras.layers.層1()(inputs)
    x = keras.layers.層2()(x)
    ...
    outputs = keras.layers.層L()(x)
    # 上で指定した処理をするモデルのオブジェクトを作る
    model = keras.Model(inputs=inputs, outputs=outputs)
    ```
- クラス継承：
    ```python
    class MyModel(keras.Model):
        def __init__(self):
            # 内部パラメータなどの情報
            super().__init__()
            self.層1 = keras.layers.層1()
            self.層2 = keras.layers.層2()
            ...
            self.層L = keras.layers.層L()

        def call(self, inputs):
            # 実際のニューラルネット処理
            x = self.層1(inputs)
            x = self.層2(x)
            ...
            outputs = self.層L(x)
            return outputs

    model = MyModel()
    ```
- モデル作成用の関数：

    初めの例で使ったAPIです。
    ```python
    # リストに先頭から順に作用させたい処理を並べる方法
    model = keras.Sequential([
        keras.Input(shape=入力のshape),
        keras.layers.層1(),
        keras.layers.層2(),
        ...
        keras.layers.層L()
    ])
    ```
    あるいは以下でも同じことができます：
    ```python
    # リストで並べる代わりに .add() で順々に追加していく方法
    model = keras.Sequential()
    model.add(keras.Input(shape=入力のshape))
    model.add(keras.layers.層1())
    model.add(keras.layers.層2())
    ...
    model.add(keras.layers.層L())
    ```
    この他、`Input` を指定する代わりに `model.build(shape)` とするやり方もあるようです。

最後の関数を使うのが楽ですが、kerasの元となっているライブラリ（次回説明）では 2番目のクラス継承するやり方が多数派です。いずれも `keras.layers.層i()` を読んだ段階で、その中にパラメータ $`\theta`$ が含まれていれば、デフォルトの乱数で初期化が実行されます。初期化のやり方の設定もできます。
 
なお作ったモデルの構造の情報は以下で表示することができます。実際に望みの処理が行われているかチェックするのと、どれくらいパラメータがあるのかみるのに便利です：
```python
model.summary()
```

- 例：三種類のやり方でニューラルネット
    $`
    \begin{align*}
    \mathbb{R}^3 \to \text{Dense}\to \mathbb{R}^2 \to \text{ReLU} \to \text{Dense} \to \mathbb{R}^5 \to \text{Softmax}
    \end{align*}
    `$ を作成してみる
    <details>
    <summary>処理をベタ打ちするやり方：</summary>
    <blockquote>

    ```python
    # ニューラルネットの入力から出力までを書く
    inputs = keras.Input(shape=(3,))
    x = keras.layers.Dense(2)(inputs)
    x = keras.layers.ReLU()(x)
    x = keras.layers.Dense(5)(x)
    outputs = keras.layers.Softmax()(x)
    # 上で指定した処理をするモデルのオブジェクトを作る
    model = keras.Model(inputs=inputs, outputs=outputs)
    model.summary()
    ```
    > ```
    > Model: "functional"
    > ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
    > ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
    > ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
    > │ input_layer (InputLayer)             │ (None, 3)                   │               0 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ dense (Dense)                        │ (None, 2)                   │               8 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ re_lu (ReLU)                         │ (None, 2)                   │               0 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ dense_1 (Dense)                      │ (None, 5)                   │              15 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ softmax (Softmax)                    │ (None, 5)                   │               0 │
    > └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
    >  Total params: 23 (92.00 B)
    >  Trainable params: 23 (92.00 B)
    >  Non-trainable params: 0 (0.00 B)
    > ```

    </blockquote>
    </details>

    <details class="memo">
    <summary>クラス継承を使うやり方：</summary>

    ```python
    class MyModel(keras.Model):
        def __init__(self):
            # 内部パラメータなどの情報
            super().__init__()
            self.l1 = keras.layers.Dense(2)
            self.a1 = keras.layers.ReLU()
            self.l2 = keras.layers.Dense(5)
            self.a2 = keras.layers.Softmax()

        def call(self, inputs):
            # 実際のニューラルネット処理
            x = self.l1(inputs)
            x = self.a1(x)
            x = self.l2(x)
            outputs = self.a2(x)
            return outputs

    # 実際にモデルを作る
    model = MyModel()
    #model.build(input_shape=(None, 3))
    model(np.random.normal(0, 1, size=(1, 3)))

    model.summary()
    ```
    > ```
    > Model: "my_model"
    > ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
    > ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
    > ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
    > │ dense_2 (Dense)                      │ (1, 2)                      │               8 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ re_lu_1 (ReLU)                       │ ?                           │               0 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ dense_3 (Dense)                      │ (1, 5)                      │              15 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ softmax_1 (Softmax)                  │ ?                           │               0 │
    > └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
    >  Total params: 23 (92.00 B)
    >  Trainable params: 23 (92.00 B)
    >  Non-trainable params: 0 (0.00 B)
    > ```

    途中のshapeが自動で計算できていませんがパラメータ数は同じなので、問題なく動くはずです。

    </details>

    <details class="memo">
    <summary>モデル作成用の関数を使うやり方：</summary>

    ```python
    model = keras.Sequential([
        keras.Input(shape=(3,)),
        keras.layers.Dense(2),
        keras.layers.ReLU(),
        keras.layers.Dense(5),
        keras.layers.Softmax()
    ])

    model.summary()
    ```
    > ```
    > Model: "sequential"
    > ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
    > ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
    > ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
    > │ dense_4 (Dense)                      │ (None, 2)                   │               8 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ re_lu_2 (ReLU)                       │ (None, 2)                   │               0 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ dense_5 (Dense)                      │ (None, 5)                   │              15 │
    > ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    > │ softmax_2 (Softmax)                  │ (None, 5)                   │               0 │
    > └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
    > Total params: 23 (92.00 B)
    > Trainable params: 23 (92.00 B)
    > Non-trainable params: 0 (0.00 B)
    > ```

    </details>



$\blacksquare$ **練習問題6:** 図からモデルを作る
> [!TIP]
> <details open>
> <summary>解答例</summary>
> 
> </details>

$\blacksquare$ **練習問題7:** 図からモデルを作る2 
> [!TIP]
> <details open>
> <summary>解答例</summary>
> 
> </details>

#### 訓練

モデルオブジェクト `model` を作ったら、それの訓練をします。訓練は
1. 訓練の設定をコンパイルする
2. 訓練を実行する

の2段階からなります。ここでは「最低限」必要なコマンドを説明します。より詳しい設定も可能ですが、その場合は以下を参照してください。
- https://keras.io/api/models/model_training_apis/



##### 訓練設定のコンパイル

最低限の設定は以下です：

```python
model.compile(optimizer=keras.optimizers.更新手法名(),
              loss=keras.losses.ロス関数名() )
```
それぞれどのようなものが用意されているかは
- 更新手法：https://keras.io/api/optimizers/
- ロス関数：https://keras.io/api/losses/

を参考にしてください。また、実際に使う場合はこれだけで動かすことはほとんどなく、オプショナルな引数をつけて動かす場合が多いです。例えば `metrics` などは重要な引数で、訓練中に測りたい指標をリストで与えることで、下の訓練コマンドを動かした際に自動でその指標を図りながら訓練をしてくれるようになったりします。

##### 訓練の実行

最低限の設定は以下です

```python
model.fit(X, y, 
          batch_size=ミニバッチのサイズ（自然数）, 
          epochs=データ全体を何周するか（自然数）)
```
- 例：回帰の場合
    <details>
    <summary>データの作成</summary>
    <blockquote>
    
    ```python
    class get_noisy_sin:
        rng = np.random.default_rng(seed=1)
        
        def sample(self, N):
            x = self.rng.uniform(-3, 3, N)
            y = np.sin(x)
            noise = self.rng.normal(0, .2, N)
            is_noisy = self.rng.choice([True, False], N)
            y += is_noisy*noise
            df = pd.DataFrame({
                    "x": x.astype(np.float32),
                    "y": y.astype(np.float32),
                    "is_noisy": is_noisy
                })
            return df

    df = p.sample(3000)
    ```
    </blockquote>
    </details>
    <details>
    <summary>モデルの設定＋訓練</summary>
    <blockquote>
    
    モデルの設計は gemini が提案してきた適当なものです：
    ```python
    model = keras.models.Sequential([keras.layers.Input(shape=(1,)),
                                     keras.layers.Dense(10, activation='relu'),
                                     keras.layers.Dense(8, activation='relu'),
                                     keras.layers.Dense(1)])

    model.compile(optimizer='adam', loss='mse') # 'mse' とは mean squared error の略で、sklearnの回でも出てきた2乗誤差のことです。

    X_train = df[["x"]]
    y_train = df["y"]

    model.fit(X_train, y_train, epochs=5, batch_size=10)
    ```
    > ```
    > Epoch 1/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 0.5450
    > Epoch 2/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - loss: 0.1284
    > Epoch 3/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.0822
    > Epoch 4/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - loss: 0.0513
    > Epoch 5/5
    > 300/300 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - loss: 0.0347
    > ```
    それなりにロスが減っているので良さそうです。
    </blockquote>
    </details>
    <details>
    <summary>モデルの検証</summary>
    <blockquote>

    訓練後モデルを可視化してみましょう：
    ```python
    df_new = p.sample(300)
    sns.scatterplot(data=df_new, x="x", y="y", hue="is_noisy")

    X_test = np.linspace(-3, 3, 100).reshape(-1, 1)
    plt.plot(X_test, model.predict(X_test), color="red", label="model prediction")
    plt.legend()
    ```
    >```
    > 4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step
    > ```
    > <img src="figs/dl_reg1.jpg" width=40%></img>

    True/Falseはノイズの有無です。それなりに良いのではないかなと思います。
    
    </blockquote>
    </details>
- 例：分類の場合

    <details>
    <summary>データの作成</summary>
    <blockquote>
    
    ```python
    class DataGenerator2():
        ''' データを人工的に生成するためのクラスその2
            self.sample(N) で pd.DataFrame オブジェクトを出力
            "x0", "x1", y" がそれぞれの要素に対応
        '''
        def __init__(self, dim=2, n_class=3, seed=1):
            self.dim = dim
            self.n_class = n_class
            self.rng = np.random.default_rng(seed)
            self.mu_for_class_np = self.rng.normal(0, 1, size=(n_class, dim))
            
        def sample(self, N_batch):
            x = []
            y = []
            for n in range(self.n_class):
                mu = self.mu_for_class_np[n]
                x.append(self.rng.normal(0, .3, size=(N_batch//self.n_class, self.dim)) + mu)
                y.append(n*np.ones(shape=(N_batch//self.n_class)))
                
            x = np.concatenate(x, axis=0)
            y = np.concatenate(y, axis=0)
            
            df = pd.DataFrame(
                                {"x0": x[:, 0], 
                                "x1": x[:, 1], 
                                "y":np.array(y)}
                            )
            
            return df
        
    p = DataGenerator2()

    df = p.sample(1000)
    ```
    </blockquote>
    </details>
    <details>
    <summary>モデルの設定＋訓練</summary>


    <blockquote>
    
    モデルの設計は gemini が提案してきた適当なものです：

    ```python
    model = keras.models.Sequential([keras.layers.Input(shape=(2,)),
                                    keras.layers.Dense(10, activation='relu'),
                                    keras.layers.Dense(8, activation='relu'),
                                    keras.layers.Dense(3)])

    model.compile(optimizer='adam', 
                  loss='sparse_categorical_crossentropy', # sklearnの回でのロジスティック回帰の際のロスに対応
                  metrics=['accuracy']) # 分類の場合は metrix に 'accuracy' を入れておくと実際の分類精度が見えて良いです。

    X_train = df[["x0", "x1"]]
    y_train = df["y"]
    model.fit(X_train, y_train, epochs=5, batch_size=10)
    ```
    >```
    > Epoch 1/5
    > 100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - accuracy: 0.4421 - loss: 1.2233
    > Epoch 2/5
    > 100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.5933 - loss: 0.6911
    > Epoch 3/5
    > 100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.5525 - loss: 0.8633
    > Epoch 4/5
    > 100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.5668 - loss: 0.6114
    > Epoch 5/5
    > 100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.5684 - loss: 0.7287
    > <keras.src.callbacks.history.History at 0x7e2e69bc1c10>
    >```

    うまく訓練できていることがわかります。
    </blockquote>
    </details>
    <details>
    <summary>モデルの検証</summary>
    <blockquote>

    可視化は最初の例でもやったので大体同じです。新データによる検証だけ `model.evaluate()` を使ってやってみますと、

    ```python
    df_new = p.sample(300)
    X_test = df_new[["x0", "x1"]]
    y_test = df_new["y"]

    model.evaluate(X_test, y_test, return_dict=True)
    ```
    >```
    > 10/10 ━━━━━━━━━━━━━━━━━━━━ 2s 15ms/step - accuracy: 0.6290 - loss: 0.5510
    > {'accuracy': 0.5766666531562805, 'loss': 0.6474849581718445}
    >```

    これをみると、新データに対して精度が57%程度しか出ていないことがわかります。これは可視化するまでもなく良くないモデルであることがわかります。
    </blockquote>
    </details>


$\blacksquare$ **練習問題?:**  
> [!TIP]
> <details open>
> <summary>解答例</summary>
> 
> </details>

#### 保存・読み込み

- 詳細：https://keras.io/api/models/model_saving_apis/

作ったモデルは保存しておくことができます。また、保存されたモデルは当然読み込むことができます。色々オプションはあるようですが、基本は保存は
```python
model.save(filepath="ファイル名")
```
です。また読み込みは
```python
keras.saving.load_model(filepath="ファイル名")
```
です。

この辺りは実際に使う際に重要になると思いますが、特にモデルを個人開発する際に重要です。一方でインターネット上に存在する訓練済みモデルを読み込む際には、別のライブラリを使った方が簡単だと思います（[4-2](../section4/4-2.md)で解説予定です）。

### コールバックAPI

ここまでの説明で深層学習に最低限必要な道具は説明し終えました。しかし実際に研究/開発を進めていくとなると、上で説明したような処理を何度も繰り返すことになり、効率的に作業を進めたくなってくるはずです。特に **訓練プロセスと並行した何らかの別処理**、例えば

1. 学習率 $`\eta`$ を反復回数やエポック毎に設定しなおしたい
2. 訓練中であっても、良い精度のモデルであれば保存しておきたい
3. ロス関数をはじめとした色々な指標を訓練中/訓練後にもチェックできるようにしたい

などができると良さそうです。例えば3の指標を見ながら、一番良さそうな段階のモデルを2で保存しておいたものの中から取り出す、といったことが可能になります。

このような処理を **コールバック** と言います。コールバックは
```python
model.fit(..., callbacks=[処理1, 処理2, ...])
```
と `model.fit()` の引数としてリストにして渡すと、良きタイミングで望みの処理が自動的に入ることになるため、効率的な開発の助けになります。

#### 訓練のやり方に関わるコールバック

##### 学習率のスケジュール



##### 早期終了

#### 訓練記録用のコールバック

##### CSVログ

##### checkpoint

##### Tensorboard


## 学習結果可視化用ライブラリ `Tensorboard`

深層学習の数値実験では数多くの数値を取り扱います。例えば
- ニューラルネットワークのパラメータ
- 学習ループ中の精度やロス関数の値
- 勾配更新に用いるパラメータの情報

などが挙げられます。これらの情報は数値実験毎に外部ファイル（こういうのを**ログ**と言います）としておいておくのが良いです。素朴にテキストファイルとして保存しておいても良いのですが、`tensorboard` というライブラリを用いることで、ブラウザ機能による便利な可視化の恩恵を受けることができます。また、生データを後から取り出すこともできるため、実際に matplotlib などでグラフを書いたりもできます。

### 使い方

### ログの読み方

## コラム：Define and run と define by run


